# -*- coding: utf-8 -*-
"""DLLAB3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f09ze4bfbJHbGqfBo4GzzPou1OMnR3eS
"""

"""aNALYSIS OF ACTIVATION FUNCTIONS IN MULTILAYER PERCEPTRON"""
"""
IRIS DATASET
random state - randomly pick , when doing repeated executions we should get sameoutput

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LeakyReLU
from tensorflow.keras.optimizers import Adam
from  tensorflow.keras.utils import to_categorical

iris = load_iris()
x = iris.data[:, :2] #twp features for visualisation
y = iris.target
y_onehot = to_categorical(y,num_classes=3)
#encoder = OneHotEncoder(sparse=False)
#y_encoder = encoder.fit_transform(y)
X_train, X_test, y_train, y_test = train_test_split(x, y_onehot, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

def build_mlp(activation):
  model = Sequential()
  model.add(Dense(16, input_shape=(2,)))
  if activation == 'leaky_relu': #y only if for leakyrelu becoz we need alpha value then it will call inbuilt function
    model.add(LeakyReLU(alpha=0.01))
  else:
    model.add(Dense(8,activation= activation))

  model.add(Dense(8, activation='activation'))
  model.add(Dense(3, activation='softmax'))

  model.compile(optimizer = Adam(learning_rate = 0.01),loss = 'categorical_crossentropy', metrics = ['accuracy'])
  return model
#

activations = ["relu","tanh","leaky_relu"]
histories={}
models={}
for act in activations:
  model = build_mlp(act)
  history = model.fit(X_train,y_train,validation_data = (X_test,y_test),epochs=100,verbose=0)
  histories[act] = history
  models[act] = model

for act in activations:
  plt.plot(histories[act].history['val_accuracy'], label=act)
plt.xlabel("Epochs")
plt.ylabel(" Validation Accuracy")
plt.legend()
plt.title("Activation Function Comparison")
plt.show()



def build_mlp(activation):
  model = Sequential()
  # First hidden layer
  if activation == 'leakyrelu':
    model.add(Dense(16, input_shape=(2,)))
    model.add(LeakyReLU(negative_slope=0.01))
  else:
    model.add(Dense(16, activation=activation, input_shape=(2,)))

  # Second hidden layer
  if activation == 'leakyrelu':
    model.add(Dense(8))
    model.add(LeakyReLU(negative_slope=0.01))
  else:
    model.add(Dense(8, activation=activation))

  # Output layer
  model.add(Dense(3, activation='softmax'))

  model.compile(optimizer = Adam(learning_rate = 0.01),loss = 'categorical_crossentropy', metrics = ['accuracy'])
  return model

activations = ["relu","tanh","leakyrelu"]
histories={}
models={}
for act in activations:
  model = build_mlp(act)
  history = model.fit(X_train,y_train,validation_data = (X_test,y_test),epochs=100,verbose=0)
  histories[act] = history
  models[act] = model

for act in activations:
  plt.plot(histories[act].history['val_accuracy'], label=act)
plt.xlabel("Epochs")
plt.ylabel(" Validation Accuracy")
plt.legend()
plt.title("Activation Function Comparison")
plt.show()

from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score, confusion_matrix

def evaluate_model(model,X_test,y_test):
  y_true = np.argmax(y_test,axis = 1)
  y_pred = np.argmax(model.predict(X_test,verbose = 0),axis = 1)

  return{
      "Accuracy":accuracy_score(y_true,y_pred),
      "Precision":precision_score(y_true,y_pred,average='macro'),
      "Recall":recall_score(y_true,y_pred,average='macro'),
      "F1 Score":f1_score(y_true,y_pred,average='macro'),
      "Confusion Matrix":confusion_matrix(y_true,y_pred)
  }

result={}
for act in ["tanh", "relu", "leakyrelu"]:
  result[act] = evaluate_model(models[act],X_test,y_test)
  print(result[act]["Confusion Matrix"])
  print(result[act]["Precision"])
  print(result[act]["Recall"])
  print(result[act]["F1 Score"])
  print(result[act]["Accuracy"])